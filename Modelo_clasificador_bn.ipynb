{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Se cargan las librerías necesarias para utilizar la red convolucional \n",
    "import tensorflow\n",
    "import keras \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "# from keras.layers import Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los parámetros de entrenamiento de la red\n",
    "import os\n",
    "path_entreno_2 = '/home/cristian/Escritorio/Reconocedor facial/Datos_desarrollo/Entrenamiento_2/'\n",
    "\n",
    "epochs = 5\n",
    "altura, ancho = 250, 250\n",
    "batch_size = 37\n",
    "filtro_conv_1 = 32\n",
    "filtro_conv_2 = 64\n",
    "tamano_fitro_1 = (5,5)\n",
    "tamano_filtro_2 = (3,3)\n",
    "tamano_pool = (2,2)\n",
    "clases = 2\n",
    "lr = 0.005 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se traen los datos\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for path in range(len(os.listdir(path_entreno_2))):\n",
    "    directorio = path_entreno_2 + os.listdir(path_entreno_2)[path] + '/'\n",
    "    for image in range(len(os.listdir(directorio))):\n",
    "        imagen = cv2.imread(path_entreno_2 + os.listdir(path_entreno_2)[path] + '/' + os.listdir(directorio)[image], cv2.IMREAD_GRAYSCALE)\n",
    "        images.append(imagen)\n",
    "        labels.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2516, 250, 250) (630, 250, 250)\n"
     ]
    }
   ],
   "source": [
    "# Se definen los conjuntos de entrenamiento y test\n",
    "images, labels = np.array(images), np.array(labels) \n",
    "labels = utils.to_categorical(labels, clases)\n",
    "\n",
    "images_train, images_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = 1, shuffle = True) \n",
    "print(images_train.shape, images_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (37, 250, 250, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (37, 250, 250, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (37, 125, 125, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (37, 125, 125, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (37, 123, 123, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (37, 61, 61, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (37, 61, 61, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (37, 238144)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (37, 128)                 30482560  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (37, 2)                   258       \n",
      "=================================================================\n",
      "Total params: 30,502,146\n",
      "Trainable params: 30,502,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Se genera el modelo\n",
    "modelo = Sequential()\n",
    "modelo.add(Convolution2D(filters = filtro_conv_1,\n",
    "    batch_size = batch_size,\n",
    "    kernel_size = tamano_fitro_1,\n",
    "    padding = 'same',\n",
    "    input_shape = (altura, ancho, 1),\n",
    "    activation = 'relu'))\n",
    "modelo.add(LeakyReLU(alpha = 0.1))\n",
    "modelo.add(MaxPooling2D(pool_size = tamano_pool))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Convolution2D(filters= filtro_conv_2,\n",
    "                  kernel_size = tamano_filtro_2,\n",
    "                  activation = 'relu'))\n",
    "modelo.add(MaxPooling2D(pool_size = tamano_pool))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Flatten())\n",
    "modelo.add(Dense(128, activation = 'relu'))\n",
    "modelo.add(Dense(2, activation = 'softmax'))\n",
    "modelo.compile(loss = keras.losses.categorical_crossentropy,\n",
    "               optimizer = optimizers.Adam(lr = lr) ,\n",
    "               metrics = ['accuracy'])\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se redimensionan los datos para que se entrenen\n",
    "images_train = images_train.reshape(images_train.shape[0],\n",
    "                                    images_train.shape[1],\n",
    "                                    images_train.shape[2], 1)\n",
    "\n",
    "images_test = images_test.reshape(images_test.shape[0],\n",
    "                                    images_test.shape[1],\n",
    "                                    images_test.shape[2], 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2516 samples, validate on 630 samples\n",
      "Epoch 1/5\n",
      "2516/2516 [==============================] - 155s 61ms/step - loss: 569.4489 - accuracy: 0.7421 - val_loss: 0.5632 - val_accuracy: 0.7282\n",
      "Epoch 2/5\n",
      "2516/2516 [==============================] - 166s 66ms/step - loss: 0.5548 - accuracy: 0.7703 - val_loss: 0.5357 - val_accuracy: 0.7282\n",
      "Epoch 3/5\n",
      "2516/2516 [==============================] - 168s 67ms/step - loss: 0.5466 - accuracy: 0.7703 - val_loss: 0.5382 - val_accuracy: 0.7282\n",
      "Epoch 4/5\n",
      "2516/2516 [==============================] - 165s 66ms/step - loss: 0.5428 - accuracy: 0.7703 - val_loss: 0.5398 - val_accuracy: 0.7282\n",
      "Epoch 5/5\n",
      "2516/2516 [==============================] - 162s 64ms/step - loss: 0.5475 - accuracy: 0.7703 - val_loss: 0.5392 - val_accuracy: 0.7282\n"
     ]
    }
   ],
   "source": [
    "history = modelo.fit(images_train, y_train, \n",
    "           epochs = epochs,\n",
    "           batch_size = batch_size, \n",
    "           shuffle = True, \n",
    "           validation_data = (images_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 6s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7282282114028931"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se calcula la precisión de la red con los datos de test\n",
    "test_evaluate = modelo.evaluate(images_test, y_test, verbose = 1, batch_size = batch_size)\n",
    "test_evaluate[0]\n",
    "test_evaluate[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
